{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d074de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b4b2926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler , MinMaxScaler , RobustScaler\n",
    "from sklearn import preprocessing\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14ae1f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8683c716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38a0d798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
       "count     569.000000  ...     569.000000       569.000000   569.000000   \n",
       "mean        0.181162  ...      25.677223       107.261213   880.583128   \n",
       "std         0.027414  ...       6.146258        33.602542   569.356993   \n",
       "min         0.106000  ...      12.020000        50.410000   185.200000   \n",
       "25%         0.161900  ...      21.080000        84.110000   515.300000   \n",
       "50%         0.179200  ...      25.410000        97.660000   686.500000   \n",
       "75%         0.195700  ...      29.720000       125.400000  1084.000000   \n",
       "max         0.304000  ...      49.540000       251.200000  4254.000000   \n",
       "\n",
       "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count        569.000000         569.000000       569.000000   \n",
       "mean           0.132369           0.254265         0.272188   \n",
       "std            0.022832           0.157336         0.208624   \n",
       "min            0.071170           0.027290         0.000000   \n",
       "25%            0.116600           0.147200         0.114500   \n",
       "50%            0.131300           0.211900         0.226700   \n",
       "75%            0.146000           0.339100         0.382900   \n",
       "max            0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "count            569.000000      569.000000               569.000000   \n",
       "mean               0.114606        0.290076                 0.083946   \n",
       "std                0.065732        0.061867                 0.018061   \n",
       "min                0.000000        0.156500                 0.055040   \n",
       "25%                0.064930        0.250400                 0.071460   \n",
       "50%                0.099930        0.282200                 0.080040   \n",
       "75%                0.161400        0.317900                 0.092080   \n",
       "max                0.291000        0.663800                 0.207500   \n",
       "\n",
       "       Unnamed: 32  \n",
       "count          0.0  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c39411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id', 'Unnamed: 32'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3619f6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8815ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['diagnosis'])\n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "209d45bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40fba2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16f10e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54d1f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split ( X , y , train_size=0.9, shuffle = True ,random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8869133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                496       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 641\n",
      "Trainable params: 641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, activation='relu',input_dim=30),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam' , loss='binary_crossentropy' , metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39139f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 2s 49ms/step - loss: 0.6859 - accuracy: 0.4939 - val_loss: 0.6753 - val_accuracy: 0.6408\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.6691 - accuracy: 0.7335 - val_loss: 0.6596 - val_accuracy: 0.7864\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.6532 - accuracy: 0.8460 - val_loss: 0.6442 - val_accuracy: 0.9126\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.6364 - accuracy: 0.9193 - val_loss: 0.6270 - val_accuracy: 0.9417\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.6176 - accuracy: 0.9218 - val_loss: 0.6075 - val_accuracy: 0.9223\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5981 - accuracy: 0.9046 - val_loss: 0.5858 - val_accuracy: 0.9223\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5742 - accuracy: 0.9291 - val_loss: 0.5641 - val_accuracy: 0.9320\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5488 - accuracy: 0.9340 - val_loss: 0.5372 - val_accuracy: 0.9126\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5198 - accuracy: 0.9267 - val_loss: 0.5044 - val_accuracy: 0.9126\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4837 - accuracy: 0.9193 - val_loss: 0.4731 - val_accuracy: 0.9223\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train , y_train , epochs=10 , validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e098548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.4480 - accuracy: 0.9120 - val_loss: 0.4397 - val_accuracy: 0.9223\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4127 - accuracy: 0.9218 - val_loss: 0.4099 - val_accuracy: 0.9126\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3818 - accuracy: 0.9193 - val_loss: 0.3806 - val_accuracy: 0.9223\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3509 - accuracy: 0.9267 - val_loss: 0.3544 - val_accuracy: 0.9223\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3257 - accuracy: 0.9242 - val_loss: 0.3335 - val_accuracy: 0.9223\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3021 - accuracy: 0.9218 - val_loss: 0.3112 - val_accuracy: 0.9223\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2823 - accuracy: 0.9218 - val_loss: 0.2953 - val_accuracy: 0.9223\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2664 - accuracy: 0.9315 - val_loss: 0.2772 - val_accuracy: 0.9223\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2495 - accuracy: 0.9267 - val_loss: 0.2720 - val_accuracy: 0.9126\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2360 - accuracy: 0.9364 - val_loss: 0.2517 - val_accuracy: 0.9223\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train , y_train , epochs=10 , validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae5b3f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2257 - accuracy: 0.9315 - val_loss: 0.2449 - val_accuracy: 0.9223\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2131 - accuracy: 0.9364 - val_loss: 0.2317 - val_accuracy: 0.9223\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2047 - accuracy: 0.9438 - val_loss: 0.2255 - val_accuracy: 0.9223\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1950 - accuracy: 0.9438 - val_loss: 0.2160 - val_accuracy: 0.9223\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1871 - accuracy: 0.9462 - val_loss: 0.2078 - val_accuracy: 0.9320\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1799 - accuracy: 0.9511 - val_loss: 0.2021 - val_accuracy: 0.9320\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1728 - accuracy: 0.9487 - val_loss: 0.1991 - val_accuracy: 0.9223\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1668 - accuracy: 0.9535 - val_loss: 0.1878 - val_accuracy: 0.9417\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1636 - accuracy: 0.9438 - val_loss: 0.1861 - val_accuracy: 0.9417\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1593 - accuracy: 0.9487 - val_loss: 0.1748 - val_accuracy: 0.9320\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1509 - accuracy: 0.9487 - val_loss: 0.1807 - val_accuracy: 0.9320\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1461 - accuracy: 0.9560 - val_loss: 0.1706 - val_accuracy: 0.9417\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1424 - accuracy: 0.9584 - val_loss: 0.1678 - val_accuracy: 0.9515\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1373 - accuracy: 0.9609 - val_loss: 0.1609 - val_accuracy: 0.9417\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1369 - accuracy: 0.9511 - val_loss: 0.1601 - val_accuracy: 0.9515\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1333 - accuracy: 0.9584 - val_loss: 0.1537 - val_accuracy: 0.9417\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1258 - accuracy: 0.9658 - val_loss: 0.1583 - val_accuracy: 0.9515\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1230 - accuracy: 0.9682 - val_loss: 0.1485 - val_accuracy: 0.9417\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1196 - accuracy: 0.9682 - val_loss: 0.1492 - val_accuracy: 0.9612\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1168 - accuracy: 0.9658 - val_loss: 0.1451 - val_accuracy: 0.9612\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train , y_train , epochs=20 , validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05be4a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1148 - accuracy: 0.9682 - val_loss: 0.1427 - val_accuracy: 0.9612\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1107 - accuracy: 0.9707 - val_loss: 0.1382 - val_accuracy: 0.9515\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1080 - accuracy: 0.9658 - val_loss: 0.1380 - val_accuracy: 0.9612\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1060 - accuracy: 0.9707 - val_loss: 0.1379 - val_accuracy: 0.9612\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1024 - accuracy: 0.9707 - val_loss: 0.1313 - val_accuracy: 0.9612\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1017 - accuracy: 0.9731 - val_loss: 0.1323 - val_accuracy: 0.9612\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0991 - accuracy: 0.9780 - val_loss: 0.1285 - val_accuracy: 0.9612\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0971 - accuracy: 0.9731 - val_loss: 0.1311 - val_accuracy: 0.9709\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0942 - accuracy: 0.9756 - val_loss: 0.1261 - val_accuracy: 0.9612\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0928 - accuracy: 0.9780 - val_loss: 0.1237 - val_accuracy: 0.9612\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0905 - accuracy: 0.9780 - val_loss: 0.1251 - val_accuracy: 0.9709\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0897 - accuracy: 0.9780 - val_loss: 0.1216 - val_accuracy: 0.9709\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0872 - accuracy: 0.9780 - val_loss: 0.1249 - val_accuracy: 0.9709\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0872 - accuracy: 0.9756 - val_loss: 0.1189 - val_accuracy: 0.9806\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0843 - accuracy: 0.9780 - val_loss: 0.1207 - val_accuracy: 0.9709\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0840 - accuracy: 0.9780 - val_loss: 0.1197 - val_accuracy: 0.9709\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0809 - accuracy: 0.9829 - val_loss: 0.1147 - val_accuracy: 0.9709\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0823 - accuracy: 0.9756 - val_loss: 0.1164 - val_accuracy: 0.9709\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0794 - accuracy: 0.9853 - val_loss: 0.1126 - val_accuracy: 0.9806\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0782 - accuracy: 0.9804 - val_loss: 0.1150 - val_accuracy: 0.9709\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0771 - accuracy: 0.9780 - val_loss: 0.1116 - val_accuracy: 0.9806\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0758 - accuracy: 0.9853 - val_loss: 0.1093 - val_accuracy: 0.9709\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0749 - accuracy: 0.9829 - val_loss: 0.1094 - val_accuracy: 0.9806\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0740 - accuracy: 0.9853 - val_loss: 0.1101 - val_accuracy: 0.9806\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0728 - accuracy: 0.9829 - val_loss: 0.1094 - val_accuracy: 0.9806\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0718 - accuracy: 0.9853 - val_loss: 0.1077 - val_accuracy: 0.9806\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0707 - accuracy: 0.9853 - val_loss: 0.1062 - val_accuracy: 0.9806\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0694 - accuracy: 0.9853 - val_loss: 0.1066 - val_accuracy: 0.9806\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0694 - accuracy: 0.9853 - val_loss: 0.1061 - val_accuracy: 0.9806\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0679 - accuracy: 0.9853 - val_loss: 0.1058 - val_accuracy: 0.9806\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0671 - accuracy: 0.9853 - val_loss: 0.1048 - val_accuracy: 0.9806\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0667 - accuracy: 0.9853 - val_loss: 0.1030 - val_accuracy: 0.9806\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0663 - accuracy: 0.9829 - val_loss: 0.1038 - val_accuracy: 0.9806\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0648 - accuracy: 0.9853 - val_loss: 0.1024 - val_accuracy: 0.9806\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0653 - accuracy: 0.9853 - val_loss: 0.1046 - val_accuracy: 0.9806\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0640 - accuracy: 0.9878 - val_loss: 0.1002 - val_accuracy: 0.9806\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0632 - accuracy: 0.9853 - val_loss: 0.1022 - val_accuracy: 0.9806\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0625 - accuracy: 0.9853 - val_loss: 0.1016 - val_accuracy: 0.9806\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0619 - accuracy: 0.9853 - val_loss: 0.1003 - val_accuracy: 0.9806\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0619 - accuracy: 0.9853 - val_loss: 0.1008 - val_accuracy: 0.9806\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0613 - accuracy: 0.9853 - val_loss: 0.0987 - val_accuracy: 0.9806\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0608 - accuracy: 0.9878 - val_loss: 0.0989 - val_accuracy: 0.9806\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0601 - accuracy: 0.9829 - val_loss: 0.0981 - val_accuracy: 0.9806\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0603 - accuracy: 0.9853 - val_loss: 0.0990 - val_accuracy: 0.9806\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0588 - accuracy: 0.9853 - val_loss: 0.0973 - val_accuracy: 0.9806\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0592 - accuracy: 0.9853 - val_loss: 0.1009 - val_accuracy: 0.9806\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0586 - accuracy: 0.9853 - val_loss: 0.0979 - val_accuracy: 0.9806\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0575 - accuracy: 0.9853 - val_loss: 0.0959 - val_accuracy: 0.9806\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0570 - accuracy: 0.9853 - val_loss: 0.0982 - val_accuracy: 0.9806\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0569 - accuracy: 0.9853 - val_loss: 0.0963 - val_accuracy: 0.9806\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0570 - accuracy: 0.9878 - val_loss: 0.0974 - val_accuracy: 0.9806\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0568 - accuracy: 0.9853 - val_loss: 0.0962 - val_accuracy: 0.9806\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0557 - accuracy: 0.9853 - val_loss: 0.0967 - val_accuracy: 0.9806\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0565 - accuracy: 0.9853 - val_loss: 0.0963 - val_accuracy: 0.9806\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0550 - accuracy: 0.9878 - val_loss: 0.0973 - val_accuracy: 0.9806\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0550 - accuracy: 0.9878 - val_loss: 0.0936 - val_accuracy: 0.9806\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0536 - accuracy: 0.9853 - val_loss: 0.0966 - val_accuracy: 0.9806\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0539 - accuracy: 0.9878 - val_loss: 0.0950 - val_accuracy: 0.9806\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0539 - accuracy: 0.9853 - val_loss: 0.0946 - val_accuracy: 0.9806\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0533 - accuracy: 0.9853 - val_loss: 0.0962 - val_accuracy: 0.9806\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0539 - accuracy: 0.9853 - val_loss: 0.0924 - val_accuracy: 0.9806\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0533 - accuracy: 0.9878 - val_loss: 0.0981 - val_accuracy: 0.9806\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0533 - accuracy: 0.9829 - val_loss: 0.0914 - val_accuracy: 0.9806\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0520 - accuracy: 0.9853 - val_loss: 0.0945 - val_accuracy: 0.9806\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0522 - accuracy: 0.9878 - val_loss: 0.0950 - val_accuracy: 0.9806\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0530 - accuracy: 0.9878 - val_loss: 0.0905 - val_accuracy: 0.9806\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0529 - accuracy: 0.9853 - val_loss: 0.0982 - val_accuracy: 0.9709\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0509 - accuracy: 0.9878 - val_loss: 0.0904 - val_accuracy: 0.9806\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0510 - accuracy: 0.9853 - val_loss: 0.0928 - val_accuracy: 0.9806\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0523 - accuracy: 0.9853 - val_loss: 0.0932 - val_accuracy: 0.9806\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0503 - accuracy: 0.9878 - val_loss: 0.0914 - val_accuracy: 0.9806\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0512 - accuracy: 0.9853 - val_loss: 0.0931 - val_accuracy: 0.9806\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0534 - accuracy: 0.9829 - val_loss: 0.0903 - val_accuracy: 0.9806\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0521 - accuracy: 0.9853 - val_loss: 0.0960 - val_accuracy: 0.9709\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0492 - accuracy: 0.9878 - val_loss: 0.0905 - val_accuracy: 0.9806\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0501 - accuracy: 0.9853 - val_loss: 0.0903 - val_accuracy: 0.9806\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0535 - accuracy: 0.9853 - val_loss: 0.0963 - val_accuracy: 0.9709\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0506 - accuracy: 0.9878 - val_loss: 0.0882 - val_accuracy: 0.9806\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0491 - accuracy: 0.9878 - val_loss: 0.0962 - val_accuracy: 0.9709\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0517 - accuracy: 0.9853 - val_loss: 0.0896 - val_accuracy: 0.9806\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0503 - accuracy: 0.9878 - val_loss: 0.0941 - val_accuracy: 0.9709\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0486 - accuracy: 0.9878 - val_loss: 0.0906 - val_accuracy: 0.9806\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0509 - accuracy: 0.9829 - val_loss: 0.0891 - val_accuracy: 0.9806\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0472 - accuracy: 0.9878 - val_loss: 0.0928 - val_accuracy: 0.9806\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0475 - accuracy: 0.9878 - val_loss: 0.0916 - val_accuracy: 0.9806\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0475 - accuracy: 0.9878 - val_loss: 0.0906 - val_accuracy: 0.9806\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0483 - accuracy: 0.9878 - val_loss: 0.0931 - val_accuracy: 0.9709\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0512 - accuracy: 0.9853 - val_loss: 0.0883 - val_accuracy: 0.9806\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0491 - accuracy: 0.9853 - val_loss: 0.0988 - val_accuracy: 0.9612\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0464 - accuracy: 0.9878 - val_loss: 0.0871 - val_accuracy: 0.9806\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0478 - accuracy: 0.9853 - val_loss: 0.0890 - val_accuracy: 0.9806\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0493 - accuracy: 0.9853 - val_loss: 0.0933 - val_accuracy: 0.9709\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0464 - accuracy: 0.9853 - val_loss: 0.0867 - val_accuracy: 0.9806\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0463 - accuracy: 0.9878 - val_loss: 0.0914 - val_accuracy: 0.9709\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0460 - accuracy: 0.9878 - val_loss: 0.0918 - val_accuracy: 0.9709\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0459 - accuracy: 0.9878 - val_loss: 0.0919 - val_accuracy: 0.9709\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0465 - accuracy: 0.9878 - val_loss: 0.0902 - val_accuracy: 0.9806\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0459 - accuracy: 0.9853 - val_loss: 0.0891 - val_accuracy: 0.9806\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0454 - accuracy: 0.9878 - val_loss: 0.0893 - val_accuracy: 0.9806\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0454 - accuracy: 0.9878 - val_loss: 0.0907 - val_accuracy: 0.9709\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train , y_train , epochs=100 , validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf7f6407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0454 - accuracy: 0.9878 - val_loss: 0.0886 - val_accuracy: 0.9806\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0456 - accuracy: 0.9878 - val_loss: 0.0902 - val_accuracy: 0.9709\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0448 - accuracy: 0.9878 - val_loss: 0.0891 - val_accuracy: 0.9806\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0446 - accuracy: 0.9878 - val_loss: 0.0891 - val_accuracy: 0.9806\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0449 - accuracy: 0.9878 - val_loss: 0.0888 - val_accuracy: 0.9806\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0446 - accuracy: 0.9853 - val_loss: 0.0869 - val_accuracy: 0.9806\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0452 - accuracy: 0.9878 - val_loss: 0.0960 - val_accuracy: 0.9709\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0447 - accuracy: 0.9878 - val_loss: 0.0868 - val_accuracy: 0.9806\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0441 - accuracy: 0.9878 - val_loss: 0.0914 - val_accuracy: 0.9709\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0442 - accuracy: 0.9878 - val_loss: 0.0871 - val_accuracy: 0.9806\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0436 - accuracy: 0.9878 - val_loss: 0.0900 - val_accuracy: 0.9709\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0443 - accuracy: 0.9878 - val_loss: 0.0882 - val_accuracy: 0.9709\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0436 - accuracy: 0.9878 - val_loss: 0.0874 - val_accuracy: 0.9806\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0433 - accuracy: 0.9878 - val_loss: 0.0893 - val_accuracy: 0.9709\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0433 - accuracy: 0.9878 - val_loss: 0.0885 - val_accuracy: 0.9709\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0434 - accuracy: 0.9878 - val_loss: 0.0912 - val_accuracy: 0.9709\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0436 - accuracy: 0.9878 - val_loss: 0.0909 - val_accuracy: 0.9709\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0429 - accuracy: 0.9878 - val_loss: 0.0851 - val_accuracy: 0.9806\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0431 - accuracy: 0.9878 - val_loss: 0.0909 - val_accuracy: 0.9709\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0426 - accuracy: 0.9878 - val_loss: 0.0898 - val_accuracy: 0.9709\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0430 - accuracy: 0.9878 - val_loss: 0.0898 - val_accuracy: 0.9709\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0431 - accuracy: 0.9878 - val_loss: 0.0923 - val_accuracy: 0.9709\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0440 - accuracy: 0.9829 - val_loss: 0.0859 - val_accuracy: 0.9806\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0425 - accuracy: 0.9878 - val_loss: 0.0920 - val_accuracy: 0.9709\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0440 - accuracy: 0.9878 - val_loss: 0.0880 - val_accuracy: 0.9709\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0423 - accuracy: 0.9878 - val_loss: 0.0921 - val_accuracy: 0.9709\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0421 - accuracy: 0.9878 - val_loss: 0.0877 - val_accuracy: 0.9709\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0422 - accuracy: 0.9878 - val_loss: 0.0936 - val_accuracy: 0.9709\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0421 - accuracy: 0.9878 - val_loss: 0.0870 - val_accuracy: 0.9709\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0422 - accuracy: 0.9902 - val_loss: 0.0898 - val_accuracy: 0.9709\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0427 - accuracy: 0.9878 - val_loss: 0.0880 - val_accuracy: 0.9709\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0439 - accuracy: 0.9902 - val_loss: 0.0932 - val_accuracy: 0.9709\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0451 - accuracy: 0.9829 - val_loss: 0.0832 - val_accuracy: 0.9806\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0472 - accuracy: 0.9829 - val_loss: 0.1064 - val_accuracy: 0.9612\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0408 - accuracy: 0.9878 - val_loss: 0.0835 - val_accuracy: 0.9806\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0436 - accuracy: 0.9853 - val_loss: 0.0891 - val_accuracy: 0.9709\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0411 - accuracy: 0.9878 - val_loss: 0.0910 - val_accuracy: 0.9709\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0415 - accuracy: 0.9878 - val_loss: 0.0856 - val_accuracy: 0.9709\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0415 - accuracy: 0.9878 - val_loss: 0.0889 - val_accuracy: 0.9709\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0411 - accuracy: 0.9878 - val_loss: 0.0884 - val_accuracy: 0.9709\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0411 - accuracy: 0.9902 - val_loss: 0.0885 - val_accuracy: 0.9709\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0410 - accuracy: 0.9902 - val_loss: 0.0885 - val_accuracy: 0.9709\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0401 - accuracy: 0.9878 - val_loss: 0.0957 - val_accuracy: 0.9709\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0412 - accuracy: 0.9878 - val_loss: 0.0875 - val_accuracy: 0.9709\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0422 - accuracy: 0.9878 - val_loss: 0.0907 - val_accuracy: 0.9709\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0409 - accuracy: 0.9878 - val_loss: 0.0906 - val_accuracy: 0.9709\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0418 - accuracy: 0.9878 - val_loss: 0.0839 - val_accuracy: 0.9806\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0400 - accuracy: 0.9878 - val_loss: 0.0974 - val_accuracy: 0.9709\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0400 - accuracy: 0.9878 - val_loss: 0.0889 - val_accuracy: 0.9709\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0404 - accuracy: 0.9902 - val_loss: 0.0922 - val_accuracy: 0.9709\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0399 - accuracy: 0.9902 - val_loss: 0.0866 - val_accuracy: 0.9709\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0398 - accuracy: 0.9902 - val_loss: 0.0881 - val_accuracy: 0.9709\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0410 - accuracy: 0.9878 - val_loss: 0.0931 - val_accuracy: 0.9709\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0393 - accuracy: 0.9902 - val_loss: 0.0893 - val_accuracy: 0.9709\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0395 - accuracy: 0.9902 - val_loss: 0.0872 - val_accuracy: 0.9709\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0395 - accuracy: 0.9878 - val_loss: 0.0934 - val_accuracy: 0.9709\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0406 - accuracy: 0.9878 - val_loss: 0.0885 - val_accuracy: 0.9709\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0391 - accuracy: 0.9902 - val_loss: 0.0966 - val_accuracy: 0.9709\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0398 - accuracy: 0.9878 - val_loss: 0.0891 - val_accuracy: 0.9709\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0398 - accuracy: 0.9878 - val_loss: 0.0948 - val_accuracy: 0.9709\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0393 - accuracy: 0.9878 - val_loss: 0.0920 - val_accuracy: 0.9709\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0410 - accuracy: 0.9878 - val_loss: 0.0913 - val_accuracy: 0.9709\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0388 - accuracy: 0.9878 - val_loss: 0.0943 - val_accuracy: 0.9709\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0396 - accuracy: 0.9902 - val_loss: 0.0887 - val_accuracy: 0.9709\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0387 - accuracy: 0.9902 - val_loss: 0.0903 - val_accuracy: 0.9709\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0388 - accuracy: 0.9902 - val_loss: 0.0999 - val_accuracy: 0.9709\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 0.0893 - val_accuracy: 0.9709\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0387 - accuracy: 0.9902 - val_loss: 0.0897 - val_accuracy: 0.9709\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0396 - accuracy: 0.9902 - val_loss: 0.0908 - val_accuracy: 0.9709\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0405 - accuracy: 0.9853 - val_loss: 0.0879 - val_accuracy: 0.9709\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0382 - accuracy: 0.9902 - val_loss: 0.0947 - val_accuracy: 0.9709\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 0.0910 - val_accuracy: 0.9709\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0393 - accuracy: 0.9853 - val_loss: 0.0865 - val_accuracy: 0.9709\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0382 - accuracy: 0.9878 - val_loss: 0.0967 - val_accuracy: 0.9709\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0385 - accuracy: 0.9902 - val_loss: 0.0909 - val_accuracy: 0.9709\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0382 - accuracy: 0.9902 - val_loss: 0.0961 - val_accuracy: 0.9709\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0377 - accuracy: 0.9902 - val_loss: 0.0912 - val_accuracy: 0.9709\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0413 - accuracy: 0.9902 - val_loss: 0.0872 - val_accuracy: 0.9709\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0447 - accuracy: 0.9804 - val_loss: 0.1015 - val_accuracy: 0.9709\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0372 - accuracy: 0.9902 - val_loss: 0.0859 - val_accuracy: 0.9709\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0388 - accuracy: 0.9878 - val_loss: 0.0861 - val_accuracy: 0.9709\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0369 - accuracy: 0.9878 - val_loss: 0.1025 - val_accuracy: 0.9709\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0379 - accuracy: 0.9902 - val_loss: 0.0916 - val_accuracy: 0.9709\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 0.0877 - val_accuracy: 0.9709\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0369 - accuracy: 0.9902 - val_loss: 0.0952 - val_accuracy: 0.9709\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0375 - accuracy: 0.9902 - val_loss: 0.0938 - val_accuracy: 0.9709\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0379 - accuracy: 0.9902 - val_loss: 0.0907 - val_accuracy: 0.9709\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0370 - accuracy: 0.9902 - val_loss: 0.0917 - val_accuracy: 0.9709\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0395 - accuracy: 0.9878 - val_loss: 0.0982 - val_accuracy: 0.9709\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0404 - accuracy: 0.9853 - val_loss: 0.0898 - val_accuracy: 0.9709\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0376 - accuracy: 0.9902 - val_loss: 0.0945 - val_accuracy: 0.9709\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 0.0932 - val_accuracy: 0.9709\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0376 - accuracy: 0.9878 - val_loss: 0.0934 - val_accuracy: 0.9709\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0370 - accuracy: 0.9902 - val_loss: 0.0938 - val_accuracy: 0.9709\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0364 - accuracy: 0.9902 - val_loss: 0.0919 - val_accuracy: 0.9709\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0372 - accuracy: 0.9902 - val_loss: 0.0896 - val_accuracy: 0.9709\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0364 - accuracy: 0.9902 - val_loss: 0.1003 - val_accuracy: 0.9709\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0364 - accuracy: 0.9902 - val_loss: 0.0925 - val_accuracy: 0.9709\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0373 - accuracy: 0.9878 - val_loss: 0.0899 - val_accuracy: 0.9709\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0360 - accuracy: 0.9902 - val_loss: 0.0969 - val_accuracy: 0.9709\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0364 - accuracy: 0.9902 - val_loss: 0.0941 - val_accuracy: 0.9709\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0378 - accuracy: 0.9878 - val_loss: 0.0884 - val_accuracy: 0.9709\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0391 - accuracy: 0.9878 - val_loss: 0.1115 - val_accuracy: 0.9709\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0378 - accuracy: 0.9853 - val_loss: 0.0857 - val_accuracy: 0.9612\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0367 - accuracy: 0.9902 - val_loss: 0.0967 - val_accuracy: 0.9709\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0375 - accuracy: 0.9878 - val_loss: 0.0992 - val_accuracy: 0.9709\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0381 - accuracy: 0.9853 - val_loss: 0.0890 - val_accuracy: 0.9709\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0358 - accuracy: 0.9902 - val_loss: 0.1018 - val_accuracy: 0.9709\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0369 - accuracy: 0.9902 - val_loss: 0.0912 - val_accuracy: 0.9709\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0361 - accuracy: 0.9878 - val_loss: 0.0946 - val_accuracy: 0.9709\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.1080 - val_accuracy: 0.9709\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0360 - accuracy: 0.9902 - val_loss: 0.0907 - val_accuracy: 0.9709\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0366 - accuracy: 0.9878 - val_loss: 0.0920 - val_accuracy: 0.9709\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0378 - accuracy: 0.9878 - val_loss: 0.1071 - val_accuracy: 0.9709\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0350 - accuracy: 0.9902 - val_loss: 0.0929 - val_accuracy: 0.9709\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0355 - accuracy: 0.9902 - val_loss: 0.0929 - val_accuracy: 0.9709\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0352 - accuracy: 0.9902 - val_loss: 0.0986 - val_accuracy: 0.9709\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0358 - accuracy: 0.9878 - val_loss: 0.0989 - val_accuracy: 0.9709\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0361 - accuracy: 0.9902 - val_loss: 0.1049 - val_accuracy: 0.9709\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0350 - accuracy: 0.9878 - val_loss: 0.0897 - val_accuracy: 0.9709\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0348 - accuracy: 0.9878 - val_loss: 0.1000 - val_accuracy: 0.9709\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0349 - accuracy: 0.9902 - val_loss: 0.1026 - val_accuracy: 0.9709\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0357 - accuracy: 0.9878 - val_loss: 0.0922 - val_accuracy: 0.9709\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0347 - accuracy: 0.9878 - val_loss: 0.1017 - val_accuracy: 0.9709\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0356 - accuracy: 0.9902 - val_loss: 0.0972 - val_accuracy: 0.9709\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0365 - accuracy: 0.9878 - val_loss: 0.0939 - val_accuracy: 0.9709\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0373 - accuracy: 0.9902 - val_loss: 0.1012 - val_accuracy: 0.9709\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0350 - accuracy: 0.9902 - val_loss: 0.0932 - val_accuracy: 0.9709\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0388 - accuracy: 0.9878 - val_loss: 0.1142 - val_accuracy: 0.9612\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0360 - accuracy: 0.9853 - val_loss: 0.0891 - val_accuracy: 0.9612\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0345 - accuracy: 0.9878 - val_loss: 0.1006 - val_accuracy: 0.9709\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0361 - accuracy: 0.9878 - val_loss: 0.1039 - val_accuracy: 0.9709\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0358 - accuracy: 0.9853 - val_loss: 0.0923 - val_accuracy: 0.9709\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0344 - accuracy: 0.9902 - val_loss: 0.1130 - val_accuracy: 0.9612\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0341 - accuracy: 0.9902 - val_loss: 0.0957 - val_accuracy: 0.9709\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0338 - accuracy: 0.9878 - val_loss: 0.0978 - val_accuracy: 0.9709\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0341 - accuracy: 0.9902 - val_loss: 0.1021 - val_accuracy: 0.9709\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0336 - accuracy: 0.9902 - val_loss: 0.1011 - val_accuracy: 0.9709\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0341 - accuracy: 0.9902 - val_loss: 0.1010 - val_accuracy: 0.9709\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0338 - accuracy: 0.9878 - val_loss: 0.0917 - val_accuracy: 0.9709\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0335 - accuracy: 0.9878 - val_loss: 0.0991 - val_accuracy: 0.9709\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0334 - accuracy: 0.9902 - val_loss: 0.1058 - val_accuracy: 0.9709\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0345 - accuracy: 0.9902 - val_loss: 0.0998 - val_accuracy: 0.9709\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0337 - accuracy: 0.9902 - val_loss: 0.0982 - val_accuracy: 0.9709\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0334 - accuracy: 0.9902 - val_loss: 0.1075 - val_accuracy: 0.9709\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0339 - accuracy: 0.9902 - val_loss: 0.0945 - val_accuracy: 0.9709\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0338 - accuracy: 0.9902 - val_loss: 0.1010 - val_accuracy: 0.9709\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0353 - accuracy: 0.9878 - val_loss: 0.1156 - val_accuracy: 0.9612\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0327 - accuracy: 0.9902 - val_loss: 0.0919 - val_accuracy: 0.9709\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0339 - accuracy: 0.9878 - val_loss: 0.1010 - val_accuracy: 0.9709\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9927 - val_loss: 0.1057 - val_accuracy: 0.9709\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0330 - accuracy: 0.9878 - val_loss: 0.0978 - val_accuracy: 0.9709\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 0.9902 - val_loss: 0.0995 - val_accuracy: 0.9709\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0337 - accuracy: 0.9902 - val_loss: 0.1081 - val_accuracy: 0.9612\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0331 - accuracy: 0.9902 - val_loss: 0.0957 - val_accuracy: 0.9709\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0335 - accuracy: 0.9902 - val_loss: 0.1041 - val_accuracy: 0.9709\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0329 - accuracy: 0.9902 - val_loss: 0.1086 - val_accuracy: 0.9709\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0332 - accuracy: 0.9902 - val_loss: 0.0938 - val_accuracy: 0.9612\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 0.9878 - val_loss: 0.1039 - val_accuracy: 0.9709\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0338 - accuracy: 0.9902 - val_loss: 0.1105 - val_accuracy: 0.9612\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0339 - accuracy: 0.9902 - val_loss: 0.0935 - val_accuracy: 0.9612\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0320 - accuracy: 0.9902 - val_loss: 0.1136 - val_accuracy: 0.9612\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0333 - accuracy: 0.9878 - val_loss: 0.1024 - val_accuracy: 0.9709\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0317 - accuracy: 0.9878 - val_loss: 0.1115 - val_accuracy: 0.9612\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0327 - accuracy: 0.9902 - val_loss: 0.1046 - val_accuracy: 0.9709\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0323 - accuracy: 0.9878 - val_loss: 0.1066 - val_accuracy: 0.9709\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0320 - accuracy: 0.9902 - val_loss: 0.1036 - val_accuracy: 0.9709\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0323 - accuracy: 0.9902 - val_loss: 0.1076 - val_accuracy: 0.9709\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0347 - accuracy: 0.9878 - val_loss: 0.1034 - val_accuracy: 0.9709\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0356 - accuracy: 0.9878 - val_loss: 0.1206 - val_accuracy: 0.9612\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0341 - accuracy: 0.9878 - val_loss: 0.0981 - val_accuracy: 0.9709\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.1138 - val_accuracy: 0.9612\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0324 - accuracy: 0.9902 - val_loss: 0.1032 - val_accuracy: 0.9709\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0328 - accuracy: 0.9902 - val_loss: 0.1031 - val_accuracy: 0.9709\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0323 - accuracy: 0.9902 - val_loss: 0.1101 - val_accuracy: 0.9709\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0320 - accuracy: 0.9878 - val_loss: 0.1052 - val_accuracy: 0.9709\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0310 - accuracy: 0.9902 - val_loss: 0.1157 - val_accuracy: 0.9612\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 0.9878 - val_loss: 0.1019 - val_accuracy: 0.9709\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0311 - accuracy: 0.9902 - val_loss: 0.1099 - val_accuracy: 0.9709\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0313 - accuracy: 0.9878 - val_loss: 0.1065 - val_accuracy: 0.9709\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0316 - accuracy: 0.9878 - val_loss: 0.1089 - val_accuracy: 0.9612\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0311 - accuracy: 0.9878 - val_loss: 0.1020 - val_accuracy: 0.9709\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 0.1145 - val_accuracy: 0.9612\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0319 - accuracy: 0.9878 - val_loss: 0.1032 - val_accuracy: 0.9709\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0305 - accuracy: 0.9878 - val_loss: 0.1123 - val_accuracy: 0.9612\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0310 - accuracy: 0.9902 - val_loss: 0.1096 - val_accuracy: 0.9612\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 0.9878 - val_loss: 0.1074 - val_accuracy: 0.9612\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0310 - accuracy: 0.9878 - val_loss: 0.1116 - val_accuracy: 0.9612\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0318 - accuracy: 0.9902 - val_loss: 0.1066 - val_accuracy: 0.9709\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0306 - accuracy: 0.9902 - val_loss: 0.1177 - val_accuracy: 0.9612\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0303 - accuracy: 0.9902 - val_loss: 0.1103 - val_accuracy: 0.9612\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.1049 - val_accuracy: 0.9709\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0307 - accuracy: 0.9927 - val_loss: 0.1198 - val_accuracy: 0.9612\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0307 - accuracy: 0.9902 - val_loss: 0.1051 - val_accuracy: 0.9709\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0310 - accuracy: 0.9902 - val_loss: 0.1073 - val_accuracy: 0.9709\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0322 - accuracy: 0.9902 - val_loss: 0.1113 - val_accuracy: 0.9612\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0315 - accuracy: 0.9902 - val_loss: 0.1102 - val_accuracy: 0.9612\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0326 - accuracy: 0.9878 - val_loss: 0.1073 - val_accuracy: 0.9709\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 0.1176 - val_accuracy: 0.9612\n",
      "Epoch 200/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0305 - accuracy: 0.9902 - val_loss: 0.1049 - val_accuracy: 0.9709\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train , y_train , epochs=200 , validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d54c021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred_ada_5 =model.predict(X_test)\n",
    "Y_pred_ada_5 = (model.predict(X_test) > 0.9).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f3856db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40  0]\n",
      " [ 1 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.976     1.000     0.988        40\n",
      "           1      1.000     0.941     0.970        17\n",
      "\n",
      "    accuracy                          0.982        57\n",
      "   macro avg      0.988     0.971     0.979        57\n",
      "weighted avg      0.983     0.982     0.982        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, Y_pred_ada_5))\n",
    "print(classification_report(y_test, Y_pred_ada_5, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
